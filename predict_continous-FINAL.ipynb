{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        TimeDistributed(Conv1D(16,3, activation='relu', padding = \"same\"),input_shape=[45,18,2]),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        #TimeDistributed(MaxPooling1D()),\n",
    "        TimeDistributed(Dropout(0.5)),\n",
    "        #TimeDistributed(Conv1D(64,3, activation='relu',padding = \"same\")),\n",
    "        BatchNormalization(),\n",
    "        #TimeDistributed(Dropout(0.8)),\n",
    "        TimeDistributed(Flatten()),\n",
    "        #TimeDistributed(Dense(30,activation='softmax')),  \n",
    "        LSTM(20,unit_forget_bias = 0.5, return_sequences = True),\n",
    "        TimeDistributed(Dense(6,activation='softmax'))        \n",
    "    ])\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asanas = {0:'bhujangasan', 1:'padamasan', 2:'shavasan', 3:'tadasan', 4:'trikonasan', 5:'vrikshasan'}\n",
    "\n",
    "model = get_model()\n",
    "model.load_weights(\"FINAL/weights/val1-73-0.9992.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addToPred(Xch,count,Xarr,Xlist,seq):\n",
    "    Xarr[count] = Xch\n",
    "    count = count + 1\n",
    "    #print(count)\n",
    "    if count == 45:\n",
    "        #print('Hello2')\n",
    "        Xtemp = []\n",
    "        Xtemp.append(Xarr)\n",
    "        Xlist[seq] = Xarr\n",
    "        Xarr = np.empty((45,18,2))\n",
    "        count = 0\n",
    "        seq  = seq + 1\n",
    "        #printing prediction for first frame        \n",
    "        Yht_pred = model.predict(np.asarray(Xtemp))\n",
    "        Y_pred = np.argmax(Yht_pred[0],axis = 1)\n",
    "        Y_pred_asanas = np.array([asanas[a] for a in Y_pred])\n",
    "        \n",
    "        print(\"Prediction \" + \" is \" + str(Y_pred_asanas[0]))\n",
    "        \n",
    "    #print(count)\n",
    "    return seq, count , Xarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePred(filename,count,Xarr,Xlist,seq):\n",
    "    with open(filename) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            for person in d['people']:\n",
    "                A = []\n",
    "                A = [person['pose_keypoints']]\n",
    "                #A = [person['pose_keypoints_2d']]\n",
    "                \n",
    "                X = np.asarray(A)\n",
    "                even = np.arange(0, X.shape[1], 3)\n",
    "                odd = np.arange(1, X.shape[1], 3)\n",
    "                X1 =  X[:,even]\n",
    "                X2 = X[:,odd]\n",
    "                Xch = np.dstack((X1,X2))\n",
    "                seq ,count, Xarr = addToPred(Xch,count,Xarr,Xlist,seq)\n",
    "                json_data.close\n",
    "    return seq, count, Xarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction  is bhujangasan\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "seq = 0\n",
    "Xarr = np.empty((45,18,2))\n",
    "Xlist = np.empty((1000,45,18,2))\n",
    "#print(Xarr.shape)\n",
    "lastRead = \"none\"\n",
    "timeout = time.time() + 1\n",
    "\n",
    "while(True):\n",
    "    #print(count)\n",
    "    list_of_files = glob.glob(\"output/*\")\n",
    "    #list_of_files = glob.glob(\"C:/Users/JLR/Desktop/yoga/openpose-windows/output/*\")\n",
    "    #latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    if lastRead != latest_file:\n",
    "        try:\n",
    "            seq, count, Xarr = makePred(latest_file,count,Xarr,Xlist,seq)\n",
    "            timeout = time.time() + 5 # will give result if no new file for 5 secs\n",
    "        except:\n",
    "            print \"Frame issue\"\n",
    "    if time.time() > timeout:\n",
    "        break\n",
    "    lastRead = latest_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
